For a filesystem with writing you must have truncate as well as write.
I'm not sure if flush is necessary (since it doesn't do anything) but I have
it in there anyway. There also seems to be a weird problem associated with
disk monitors. Whenever I had gvfs monitor running it would look for some 
info and autorun files one my newly mounted directory. I'm not sure why this
would cause the filesystem to crash (it didn't *seem* to be matter of
recursion since there were only a few getattr calls and none of them would
give a directory name. Anyway.

There are some tags (like file type tags) that you might not want to see
in every directory because they would be distracting/uneccesary. I think a
suitable alternative is to have those directories list as dot directories
so that they are hidden while you can still cd to those directories without
the dot. It shouldn't create any conflicts since tags with filetype names
should refer to files with that type. That all is ultimately up to the user
though.

Tag Types 
----------
The tag types are given in the name.types file corresponding to the name.db file for a tagdb.
A tag's type is created when the tag is created and saved when the database is saved. No code
other than that dealing with the actual storage and retrieval of the database files
cares about the inclusion of types. However, including them allows us to do some pretty fancy
stuff without knowing about the type of a tag beforehand.

[This is now out of date, see the code for actual implementation]
In terms of actual code, the tagdb struct gets a new member tag_types a pointer to GHashTable.
This table has the form
{ tag_code_1=>value_type_1,
    tag_code_2=>value_type_2, ...}
Where
    tag_code_n is an integer tag_code which must be the same as those for the other tables--
    that is, it uses tag_codes for the "tag_code" s :p
and 
    value_type_n is an integer type code corresponding to those in types.h. These are also
    the ones used for query results. Note that the types include record types which may not
    be translatable into persistant disk storage easily.

The method that fills this data structure from name.types must skip the comments in this file
(they start with #) and for every non-comment line, 
    1) read in the tag name (all chars upto ':') and associate it with a code
    2) read in the type (everything after the ':') and convert it to an integer (like atoi)
    3) Store the tag name and type into the tag_types structure
There isn't a real sanity check for this process, but if a tag shows up twice, we just
give it the type of the last entry.

Once we have the tag_types structure we can dispatch on tag type like:
    switch (tagdb_get_tag_type(db, tag))
    {
        case (tagdb_dict_t):
            //do dict stuff
        case (tagdb_str_t):
            //do string stuff
    }
or use a function table since switch statements are EVIL (yeah, right). Also, when reading in
the database, reading in types should obviously be done before reading in the tags so we know
how to store the data we get in there.

Sending commands/queries to the tag db
--------------------------------------
To communicate directly with the tag database, we have a special file called #LISTEN# that
clients can write to from any location in the filesystem. The #LISTEN# file is not listed
in any readdir calls, but the name is hard coded into the filesystem but may be moved to a
configuration file in the future. Clients write to #LISTEN# with a query among those listed
in the cmd_query function. A message queue is created, named with the <process_id> of the
calling process. To get the result of the query back, the client must read the file
#QREAD-<process_id>#. The content of this file is a string representation of the result
which, if it is a list, will be a list of comma-separated values or if it is a dict, it will
be the same but with each item in the list being a colon-separated pair for easy processing
with a split command.

The typical flow for working with queries on files is to first do a SEARCH query to get a 
dict of file data objects, with file IDs as the keys. These objects can then be used in 
subsequent queries by providing the file ID extracted from the object as the first argument
to the query. Using file names directly wouldn't be feasible because we allow multiples files 
to have the same name within the file system. You can, however, specify the file names or file
ids in a search query as you would any other tags.

Example (-> denotes a query sent and <- denotes a result returned) :

-> FILE SEARCH tag1 AND tag2>9000
<- <id1> <file_data1> <id2> <file_data2> <id3> <file_data3> ...
[Examine file data to get the desired files]
for i in selected_ids: 
    -> FILE ADD_TAGS i tag3:"value"
    <- (SUCCESS|FAILURE)
-> TAG COPY tag3 tag4
<- (<tag4_id> <tag4_type>|FAILURE)
[etc...]

File Collisions
---------------
How do we handle mulitple files with identical names that share some tag?
Currently, if a new file with the same name is inserted into a given file
drawer, then the old file is replaced with the new. This isn't a problem in some
cases:
    1. If the two files in question each have tags that are exclusive to one
    another, then they will be unique in those respective tag-contexts.
    2. If the files share all of the same tags, then the new file must be
    intended as a replacement for the old
Still, there is a problem with systems like makefiles where a given file might
be positioned as a node for executing makefiles in further sub-contexts. If the
sub-context makefiles were written after the parent, the parent would get
overwritten:
    parent : main.c Makefile
    child1 : foo.c Makefile
    child2 : bar.c Makefile
We could even have multiple source files with the same name (not saying this is
a good idea, but it could happen) or, in the case of some version control
schemes, a special kind of directory that appears in every project directory.
There's even a problem with plain-old replacement of a file: we count a new
entry for the tag union every time a file is inserted into a file drawer, but
don't check to see if that file is actually new. It wouldn't be too hard to do
that, but to do a check wouldn't solve the whole problem. Instead, what I could
do is have...[don't remember where I was going with this]. 

Alternative solution: NO NAMES
I went into this before, but it is the cleanest way to surmount these problems
(kind of) in terms of design. Earlier on, I had a special tag called the "name"
tag which held the name. Modifying this tag for all of the name operations
became unweildy so I abandoned that special tag approach and simply made the 
file's name a part of the file's struct. Of course, that leads to the problems
I have above with duplicate entries. Now, I want to return to that time where
things were more generic and files only needed an id number to be identified.
My idea from before was that what we really meant by file names denoted 
something about what they were about or used for and thus were the same thing
as a tag. Whereas originally I decided that "name" in itself should be a tag, 
now I think that the name should be a tag on the first-class level rather than
being a value for "name". Among the many other tags that the file has, one of
them can be the name for the file. So all README files will be tagged with
'readme' and have a special indicator on the file that 'readme' is the name of
the file as well.

Even with all of these things, my concern is coming to be how we can make this
machinery convenient to use. People make ad-hoc naming schemes all the time in
their files, numbering them according to order of creation, trial number, tv 
series order, etc. or naming files by sub-types or something of that nature.
They want these conventions to be effective in whatever interface they use like
with numbering, typically they have access to sorts. What I understand from
this is that what will make or break Tagfs is how robust its query language is
and how well I can structure interfaces with the API I present.
