For a filesystem with writing you must have truncate as well as write.
I'm not sure if flush is necessary (since it doesn't do anything) but I have
it in there anyway. There also seems to be a weird problem associated with
disk monitors. Whenever I had gvfs monitor running it would look for some 
info and autorun files one my newly mounted directory. I'm not sure why this
would cause the filesystem to crash (it didn't *seem* to be matter of
recursion since there were only a few getattr calls and none of them would
give a directory name. Anyway.

There are some tags (like file type tags) that you might not want to see
in every directory because they would be distracting/uneccesary. I think a
suitable alternative is to have those directories list as dot directories
so that they are hidden while you can still cd to those directories without
the dot. It shouldn't create any conflicts since tags with filetype names
should refer to files with that type. That all is ultimately up to the user
though.

Tag Types 
----------
The tag types are given in the name.types file corresponding to the name.db file for a tagdb.
A tag's type is created when the tag is created and saved when the database is saved. No code
other than that dealing with the actual storage and retrieval of the database files
cares about the inclusion of types. However, including them allows us to do some pretty fancy
stuff without knowing about the type of a tag beforehand.

[This is now out of date, see the code for actual implementation]
In terms of actual code, the tagdb struct gets a new member tag_types a pointer to GHashTable.
This table has the form
{ tag_code_1=>value_type_1,
    tag_code_2=>value_type_2, ...}
Where
    tag_code_n is an integer tag_code which must be the same as those for the other tables--
    that is, it uses tag_codes for the "tag_code" s :p
and 
    value_type_n is an integer type code corresponding to those in types.h. These are also
    the ones used for query results. Note that the types include record types which may not
    be translatable into persistant disk storage easily.

The method that fills this data structure from name.types must skip the comments in this file
(they start with #) and for every non-comment line, 
    1) read in the tag name (all chars upto ':') and associate it with a code
    2) read in the type (everything after the ':') and convert it to an integer (like atoi)
    3) Store the tag name and type into the tag_types structure
There isn't a real sanity check for this process, but if a tag shows up twice, we just
give it the type of the last entry.

Once we have the tag_types structure we can dispatch on tag type like:
    switch (tagdb_get_tag_type(db, tag))
    {
        case (tagdb_dict_t):
            //do dict stuff
        case (tagdb_str_t):
            //do string stuff
    }
or use a function table since switch statements are EVIL (yeah, right). Also, when reading in
the database, reading in types should obviously be done before reading in the tags so we know
how to store the data we get in there.

Sending commands/queries to the tag db
--------------------------------------
To communicate directly with the tag database, we have a special file called #LISTEN# that
clients can write to from any location in the filesystem. The #LISTEN# file is not listed
in any readdir calls, but the name is hard coded into the filesystem but may be moved to a
configuration file in the future. Clients write to #LISTEN# with a query among those listed
in the cmd_query function. A message queue is created, named with the <process_id> of the
calling process. To get the result of the query back, the client must read the file
#QREAD-<process_id>#. The content of this file is a string representation of the result
which, if it is a list, will be a list of comma-separated values or if it is a dict, it will
be the same but with each item in the list being a colon-separated pair for easy processing
with a split command.

The typical flow for working with queries on files is to first do a SEARCH query to get a 
dict of file data objects, with file IDs as the keys. These objects can then be used in 
subsequent queries by providing the file ID extracted from the object as the first argument
to the query. Using file names directly wouldn't be feasible because we allow multiples files 
to have the same name within the file system. You can, however, specify the file names or file
ids in a search query as you would any other tags.

Example (-> denotes a query sent and <- denotes a result returned) :

-> FILE SEARCH tag1 AND tag2>9000
<- <id1> <file_data1> <id2> <file_data2> <id3> <file_data3> ...
[Examine file data to get the desired files]
for i in selected_ids: 
    -> FILE ADD_TAGS i tag3:"value"
    <- (SUCCESS|FAILURE)
-> TAG COPY tag3 tag4
<- (<tag4_id> <tag4_type>|FAILURE)
[etc...]
